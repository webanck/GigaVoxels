//BVHTrianglesManip.hcu
#ifndef BVHTrianglesManip_hcu
#define BVHTrianglesManip_hcu

// Gigavoxels
//#include <GvCore/IntersectionTests.hcu>
#include <GvRendering/GvRendererHelpersKernel.h>

//#include "RendererHelpers.hcu"
//
//#include "GPUTreeBVH.hcu"
//#include "IntersectionTests.h"

/******************************************************************************
 * ...
 ******************************************************************************/
__device__
void groupParallelSum( uint Tid, int* data, uint n )
{
	for ( uint stride = n >> 1; stride > 0; stride = stride >> 1 )
	{
		// Thread Synchronization
		__syncthreads();

		if ( Tid < stride )
		{
			data[ Tid ] += data[ Tid + stride ];
		}
	}
}

/******************************************************************************
 * ...
 ******************************************************************************/
__device__
void groupParallelSum( uint Tid, float* data, uint n )
{
	for ( uint stride = n >> 1; stride > 0; stride = stride >> 1 )
	{
		// Thread Synchronization
		__syncthreads();

		if ( Tid < stride )
		{
			data[ Tid ] += data[ Tid + stride ];
		}
	}
}

/******************************************************************************
 * ...
 ******************************************************************************/
__device__
void groupParallelMin( uint Tid, float* data, uint n )
{
	for ( uint stride = n >> 1; stride > 0; stride = stride >> 1 )
	{
		if ( Tid < stride )
		{
			data[ Tid ] = data[ Tid ] <= data[ Tid + stride ] ? data[ Tid ] : data[ Tid + stride ];
			//data[Tid]=fminf(data[Tid], data[Tid+stride]);
		}

		// Thread Synchronization
		__syncthreads();
	}
}

/******************************************************************************
 * ...
 ******************************************************************************/
__device__
inline void groupParallelOR( uint Tid, uint* data, uint n )
{
	for ( uint stride = n >> 1; stride > 0; stride = stride >> 1 )
	{
		// Thread Synchronization
		__syncthreads();

		if ( Tid < stride )
		{
			data[ Tid ] = data[ Tid ] | data[ Tid + stride ];
		}
	}
}

/******************************************************************************
 ****************************** CLASS DEFINITION ******************************
 ******************************************************************************/

/** 
 * @class TraversalStack
 *
 * @brief The TraversalStack class provides ...
 *
 * @param T
 */
/** BVH traversal using shared stack. 'Realtime Ray Tracing on GPU with BVH-based Packet Traversal' */
template< class T >
class TraversalStack
{
	
	/**************************************************************************
	 ***************************** PUBLIC SECTION *****************************
	 **************************************************************************/

public:

	/****************************** INNER TYPES *******************************/

	/******************************* ATTRIBUTES *******************************/

	/**
	 * ...
	 */
	int curIndex;

	/**
	 * ...
	 */
	T data[ BVH_TRAVERSAL_STACK_SIZE ];

	/******************************** METHODS *********************************/

	/**
	 * ...
	 */
	__device__
	void init( uint Pid )
	{
		if ( Pid == 0 )
		{
			curIndex = 0;
		}

		// Thread Synchronization
		__syncthreads();
	}

	/**
	 * ...
	 */
	__device__
	inline T& top()
	{
		return data[ curIndex ];
	}

	/**
	 * ...
	 */
	__device__
	inline T pop( uint Pid )
	{
		if ( Pid == 0 && curIndex > 0 )
		{
			curIndex--;
		}
		//__syncthreads();
		return data[ curIndex ];
	}

	/**
	 * ...
	 */
	__device__
	inline T pop()
	{
		//if(curIndex>0)
			curIndex--;
		return data[ curIndex ];
	}

	/**
	 * ...
	 */
	__device__
	inline void push( uint Pid, const T& val )
	{
		if ( Pid == 0 )
		{
			if ( curIndex < BVH_TRAVERSAL_STACK_SIZE && curIndex >= 0 )
			{
				data[ curIndex ] = val;
				curIndex++;
			}
		}
	}

	/**
	 * ...
	 */
	__device__
	inline void push( const T& val )
	{
		//if(curIndex<BVH_TRAVERSAL_STACK_SIZE		&& curIndex>=0){
			data[ curIndex ] = val;
			curIndex++;
		//}
	}

	/**
	 * ...
	 */
	__device__
	inline bool isEmpty()
	{
		//__syncthreads();
		return ( curIndex <= 0 );
	}

	/**
	 * ...
	 */
	__device__
	inline bool isFull()
	{
		//__syncthreads();
		return ( curIndex >= BVH_TRAVERSAL_STACK_SIZE );
	}

	/**************************************************************************
	 **************************** PROTECTED SECTION ***************************
	 **************************************************************************/

protected:

	/****************************** INNER TYPES *******************************/

	/******************************* ATTRIBUTES *******************************/

	/******************************** METHODS *********************************/

	/**************************************************************************
	 ***************************** PRIVATE SECTION ****************************
	 **************************************************************************/

private:

	/****************************** INNER TYPES *******************************/

	/******************************* ATTRIBUTES *******************************/

	/******************************** METHODS *********************************/

};

/** 
 * @struct CudaQueue
 *
 * @brief The CudaQueue struct provides ...
 *
 * @param T ...
 * @param Size ...
 */
template< class T, uint Size >
struct CudaQueue
{

	T data[ Size ];

	__device__
	inline void clear( T v )
	{
		switch ( Size )
		{
			case 8:
				data[7]=v;
			case 7:
				data[6]=v;
			case 6:
				data[5]=v;
			case 5:
				data[4]=v;
			case 4:
				data[3]=v;
			case 3:
				data[2]=v;
			case 2:
				data[1]=v;
			case 1:
				data[0]=v;
		}
	}


	__device__
	inline T& top()
	{
		return data[ 0 ];
	}

	__device__
	inline void push(const T& val )
	{
		switch ( Size )
		{
			case 8:
				data[7]=data[6];
			case 7:
				data[6]=data[5];
			case 6:
				data[5]=data[4];
			case 5:
				data[4]=data[3];
			case 4:
				data[3]=data[2];
			case 3:
				data[2]=data[1];
			case 2:
				data[1]=data[0];
		}

		data[0] = val;
	}
};

/**
 * ...
 */
__shared__ TraversalStack< uint > S;

/**
 * ...
 */
__shared__ TraversalStack< VolTreeBVHNodeUser > nodeStack;

/**
 * ...
 */
#define STACKALL_MODE 0

/**
 * ...
 */
template< class GPUTreeBVHType >
__device__
void d_bvhTraversalStep_SharedStack(GPUTreeBVHType &gpuTreeBVH, uint &Pid, int &maskedAt, uint2 &tileCoords, float3 &rayStart, float3 &rayDir, uint &Np, VolTreeBVHNodeUser &snode, float &t)
{
	//__shared__ VolTreeBVHNodeUser snode;
	__shared__ bool stopTraversal;

	if ( S.isEmpty() )
	{
		maskedAt=-1;
	}

	if ( Pid == 0 )
	{
		Np=S.pop();
		snode=nodeStack.pop();
	}
	__syncthreads();


	if ( Pid == 0 )
	{
		stopTraversal=true;
	}
	__syncthreads();

	if ( maskedAt != -1 && snode.hasSubNodes() )
	{
		stopTraversal=false;
	}
	__syncthreads();

	while ( ! stopTraversal )
	{
		if ( maskedAt > S.curIndex )
		{
			maskedAt = BVH_TRAVERSAL_STACK_SIZE;

			//Intersect ray with BVH node
			float interMin; float interMax;
			int objboxinter=intersectBox( rayStart, rayDir,  snode.bbMin(), snode.bbMax(), interMin, interMax);
			bool snodeInter= (objboxinter && interMax>0.0f);
			interMin=maxcc(interMin, 0.0f);

			if ( ! snodeInter )
			{
				maskedAt = S.curIndex;
			}
			else if ( interMin > t )
			{
				maskedAt = S.curIndex;
			}
		}
		__syncthreads();
		
		__shared__ VolTreeBVHNodeUser Nlr[ 2 ];
		__shared__ uint sharedHits[ 4 ];
		__shared__ float M[ NUM_RAYS_PER_BLOCK_X * NUM_RAYS_PER_BLOCK_Y ]; //BVH_NUM_THREADS_PER_BLOCK_X*BVH_NUM_THREADS_PER_BLOCK_Y

		uint b1, b2;
		float lambda1; float lambda2;
		float mu1; float mu2;

		//Parallel fetch of the 2 childs
		gpuTreeBVH.parallelFetchBVHNode( Pid, Nlr[ 0 ], snode.getSubNodeIdx() );
		//__syncthreads();
		gpuTreeBVH.parallelFetchBVHNode( Pid, Nlr[ 1 ], snode.getSubNodeIdx() + 1 );
		//__syncthreads();

		int objboxinter;
		//Intersect ray with BVH node
		bool hitobjectLambda;
		bool hitobjectMu;

		if ( maskedAt>S.curIndex  /*&& maskedAt!=-1*/)
		{
			objboxinter=intersectBox( rayStart, rayDir,  Nlr[0].bbMin(), Nlr[0].bbMax(), lambda1, lambda2);
			hitobjectLambda=objboxinter && lambda2>0.0f;
			lambda1=maxcc(lambda1, 0.0f);


			objboxinter=intersectBox( rayStart, rayDir,  Nlr[1].bbMin(), Nlr[1].bbMax(), mu1, mu2);
			hitobjectMu=objboxinter && mu2>0.0f;
			mu1=maxcc(mu1, 0.0f);
		}
		else
		{
			hitobjectLambda=false;
			hitobjectMu=false;
		}


		b1 =(uint)(hitobjectLambda );
		b2 =(uint)(hitobjectMu );

		if ( Pid < 4 )
			sharedHits[Pid]=0;
		__syncthreads();

		sharedHits[2*b1+b2]=true;
		__syncthreads();

		if ( sharedHits[3] || (sharedHits[1] && sharedHits[2] ) )
		{
			/*if(Pid==0)
				M[0]=-1;*/
			float b2state= (b2 && mu1<lambda1) ? 1.0f : 0.0f;

			if(!b1 && !b2)
				b2state=0.5f;

			M[Pid]=2.0f* b2state -1.0f;

			__syncthreads();

			groupParallelSum( Pid, M, NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y /*BVH_NUM_THREADS_PER_BLOCK_X*BVH_NUM_THREADS_PER_BLOCK_Y*/);
			/*if(Pid==0){
				float summ=0.0f;

				for(uint ii=0; ii<NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y; ii++){
					summ+=M[ii];
				}
				M[0]=summ;
			}*/
			__syncthreads();

			if ( M[0] < 0.0f )
			{
				/*if(maskedAt>S.curIndex && !b2)
					maskedAt=S.curIndex;*/
				if(Pid==0){
					S.push(snode.getSubNodeIdx()+1);
					nodeStack.push(Nlr[1]);
				}
				__syncthreads();

				/*if(maskedAt>S.curIndex && !b1)
					maskedAt=S.curIndex;*/
				if(Pid==0)
				{
#if STACKALL_MODE
					S.push(snode.getSubNodeIdx());
					nodeStack.push(Nlr[0]);
#else
					Np=snode.getSubNodeIdx();
					snode=Nlr[0];
#endif
				}
				//__syncthreads();


			}
			else
			{
				/*if(maskedAt>S.curIndex && !b1)
					maskedAt=S.curIndex;*/
				if ( Pid == 0 )
				{
					S.push(snode.getSubNodeIdx());
					nodeStack.push(Nlr[0]);
				}
				__syncthreads();
				/*if(maskedAt>S.curIndex && !b2)
					maskedAt=S.curIndex;*/
				if ( Pid == 0 )
				{
#if STACKALL_MODE
					S.push(snode.getSubNodeIdx()+1);
					nodeStack.push(Nlr[1]);
#else
					Np=snode.getSubNodeIdx()+1;
					snode=Nlr[1];
#endif
				}
				//__syncthreads();
			}

			//__syncthreads();

		}else{

			if(sharedHits[2]){ //Warning, M[2] and M[1] cases inverted in the original paper algorithm
				if(maskedAt>S.curIndex && !b1		  /*&& maskedAt!=-1*/)
						maskedAt=S.curIndex;

				if(Pid==0){
#if STACKALL_MODE
					S.push(snode.getSubNodeIdx());
					nodeStack.push(Nlr[0]);
#else
					Np=snode.getSubNodeIdx();
					snode=Nlr[0];
#endif
				}
				//__syncthreads();
			}else if(sharedHits[1]){

				if(maskedAt>S.curIndex && !b2	 /*&& maskedAt!=-1*/)
					maskedAt=S.curIndex;

				if(Pid==0){
#if STACKALL_MODE
					S.push(snode.getSubNodeIdx()+1);
					nodeStack.push(Nlr[1]);
#else
					Np=snode.getSubNodeIdx()+1;
					snode=Nlr[1];
#endif
				}
				//__syncthreads();
			}
#if STACKALL_MODE==0
			else{

				if(S.isEmpty()){
					maskedAt=-1;
				}else{
					if(Pid==0){
						Np=S.pop();
						snode=nodeStack.pop();
					}
				}
				//__syncthreads();
			}
#endif

		}

		__syncthreads();

#if STACKALL_MODE
		if(S.isEmpty()){
			maskedAt=-1;
		}

		__syncthreads();
		if(Pid==0){
			Np=S.pop();
			snode=nodeStack.pop();
		}
		__syncthreads();
#endif
		if(Pid==0)
			stopTraversal=true;
		__syncthreads();

		if( maskedAt!=-1 && snode.hasSubNodes() ){
			stopTraversal=false;
		}
		__syncthreads();

	}
}


#if BVH_TRAVERSAL_USE_MASKSTACK
__shared__ TraversalStack<uint> nodeMaskStack;
#endif

template<class GPUTreeBVHType>
__device__
void d_bvhTraversalStep_SharedStack2(GPUTreeBVHType &gpuTreeBVH, uint &Pid, int &maskedAt, uint2 &tileCoords, float3 &rayStart, float3 &rayDir, uint &Np, VolTreeBVHNodeUser &snode, float &t, float &lastInterT, float &lastInterTmax){

	//__shared__ VolTreeBVHNodeUser snode;
	__shared__ bool stopTraversal;

	stopTraversal=false;


	while( !stopTraversal ){
		if(Np==0){
			if(Pid==0){
				Np=S.pop();
				snode=nodeStack.pop();
			}

#if BVH_TRAVERSAL_USE_MASKSTACK
			__shared__ uint curBlockMask;
			if(Pid==0){
				curBlockMask=nodeMaskStack.pop();
			}
			__syncthreads();

			if(maskedAt>S.curIndex ){
				if(curBlockMask & (1<<Pid)){
					maskedAt=BVH_TRAVERSAL_STACK_SIZE;
				}else{
					maskedAt=S.curIndex;
				}
			}
#endif

			__syncthreads();


#if BVH_TRAVERSAL_USE_MASKSTACK==0
			if(maskedAt>S.curIndex ){

				//Intersect ray with BVH node
				float interMin=0.0f; float interMax=1000.0f;
				int objboxinter = GvRendering::intersectBox( rayStart, rayDir,  snode.bbMin(), snode.bbMax(), interMin, interMax);
				bool snodeInter= (objboxinter && interMax>0.0f);
				//interMin=maxcc(interMin, 0.0f);

				lastInterT=interMin;
				lastInterTmax=interMax;

				float pixelSize=k_renderViewContext.pixelSize.x*(interMin* 1.333f)* k_renderViewContext.frustumNearINV*1.0f;

				if(!snodeInter || interMin>t || snode.bbox.maxSize() < pixelSize){
					maskedAt=S.curIndex;
				}else{
					maskedAt=BVH_TRAVERSAL_STACK_SIZE;
				}

			}

#endif


			if(!snode.hasSubNodes())
				break;


		} //if(Np==0)

		__shared__ VolTreeBVHNodeUser Nlr[2];
		__shared__ uint sharedHits[4];
		__shared__ float M[NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y ];


		//Parallel fetch of the 2 childs
#if 0
		gpuTreeBVH.parallelFetchBVHNode(Pid, Nlr[0], snode.getSubNodeIdx());
		//__syncthreads();
		gpuTreeBVH.parallelFetchBVHNode(Pid, Nlr[1], snode.getSubNodeIdx()+1);
		//__syncthreads();
#else
		gpuTreeBVH.parallelFetchBVHNodeTile(Pid, Nlr, snode.getSubNodeIdx());
#endif

		float interTNear[2]; float interTFar[2];
		interTNear[0]=interTNear[1]=0.0f; interTFar[0]=interTFar[1]=1000.0f;

		int objboxinter;
		//Intersect ray with BVH node
		bool hitobject[2];

		if(maskedAt>S.curIndex  /*&& maskedAt!=-1*/){
			objboxinter = GvRendering::intersectBox( rayStart, rayDir,  Nlr[0].bbMin(), Nlr[0].bbMax(), interTNear[0], interTFar[0]);
			hitobject[0]=objboxinter && interTFar[0]>0.0f;
			//interTNear[0]=maxcc(interTNear[0], 0.0f);


			objboxinter = GvRendering::intersectBox( rayStart, rayDir,  Nlr[1].bbMin(), Nlr[1].bbMax(), interTNear[1], interTFar[1]);
			hitobject[1]=objboxinter && interTFar[1]>0.0f;
			//interTNear[1]=maxcc(interTNear[1], 0.0f);

		}else{
			hitobject[0]=false;
			hitobject[1]=false;
		}



		///////////////////////
		uint b1, b2;
#if 1 //BVH_TRAVERSAL_USE_MASKSTACK
		b1 =(uint)(hitobject[0] && interTNear[0]<=t );
		b2 =(uint)(hitobject[1] && interTNear[1]<=t );
#else
		b1 =(uint)(hitobject[0]);
		b2 =(uint)(hitobject[1]);
#endif
		///////////////////////
#if BVH_TRAVERSAL_USE_MASKSTACK
		__shared__ uint blockMask[2];
#if 0
		uint maskVal[2];
		maskVal[0]=b1<<Pid;
		maskVal[1]=b2<<Pid;

		atomicOr(blockMask, maskVal[0]);
		atomicOr(blockMask+1, maskVal[1]);
#else
		__shared__ uint blockMaskList[NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y];
		blockMaskList[Pid]=b1<<Pid;
		groupParallelOR(Pid, blockMaskList, NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y);
		__syncthreads();

		if(Pid==0)
			blockMask[0]=blockMaskList[0];
		__syncthreads();

		blockMaskList[Pid]=b2<<Pid;
		groupParallelOR(Pid, blockMaskList, NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y);
		__syncthreads();

		if(Pid==0)
			blockMask[1]=blockMaskList[0];

#endif
		__syncthreads();
#endif

		///////////////////////
		if(Pid<4)
			sharedHits[Pid]=0;
		__syncthreads();

		sharedHits[2*b1+b2]=true;
		__syncthreads();

		if(  sharedHits[3] || (sharedHits[1] && sharedHits[2]) ){

			float b2state= (b2 && interTNear[1]<interTNear[0]) ? 1.0f : 0.0f;

			if(!b1 && !b2)
				b2state=0.5f;

			M[Pid]=2.0f* b2state -1.0f;

			__syncthreads();


			groupParallelSum( Pid, M, NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y );
			__syncthreads();


			if(M[0]<0.0f){

				if(Pid==0){
					S.push(snode.getSubNodeIdx()+1);
					nodeStack.push(Nlr[1]);
#if BVH_TRAVERSAL_USE_MASKSTACK
					nodeMaskStack.push(blockMask[1]);
#endif
				}
				__syncthreads();


				if(Pid==0){
					Np=snode.getSubNodeIdx();
					snode=Nlr[0];
				}
				//__syncthreads();

				lastInterT=interTNear[0];
				lastInterTmax=interTFar[0];

				if(maskedAt>S.curIndex && !b1 )
					maskedAt=S.curIndex;

			}else{

				if(Pid==0){
					S.push(snode.getSubNodeIdx());
					nodeStack.push(Nlr[0]);
#if BVH_TRAVERSAL_USE_MASKSTACK
					nodeMaskStack.push(blockMask[0]);
#endif
				}
				__syncthreads();

				if(Pid==0){
					Np=snode.getSubNodeIdx()+1;
					snode=Nlr[1];
				}
				//__syncthreads();

				lastInterT=interTNear[1];
				lastInterTmax=interTFar[1];

				if(maskedAt>S.curIndex && !b2 )
					maskedAt=S.curIndex;

			}

			//__syncthreads();

		}else{

			if(sharedHits[2]){ //Warning, M[2] and M[1] cases inverted in the original paper algorithm
				if(maskedAt>S.curIndex && !b1 )
						maskedAt=S.curIndex;

				if(Pid==0){
					Np=snode.getSubNodeIdx();
					snode=Nlr[0];
				}
				//__syncthreads();

				lastInterT=interTNear[0];
				lastInterTmax=interTFar[0];

			}else if(sharedHits[1]){

				if(maskedAt>S.curIndex && !b2 )
					maskedAt=S.curIndex;

				if(Pid==0){
					Np=snode.getSubNodeIdx()+1;
					snode=Nlr[1];
				}
				//__syncthreads();

				lastInterT=interTNear[1];
				lastInterTmax=interTFar[1];

			}
			else{

				if(S.isEmpty()){
					maskedAt=-1;
				}else{
					//Pop required
					Np=0;
				}
				//__syncthreads();
			}

		}

		__syncthreads();


		if(Pid==0)
			stopTraversal=true;
		__syncthreads();

		if( maskedAt!=-1 && (Np==0 || snode.hasSubNodes()) ){
			stopTraversal=false;
		}
		__syncthreads();

	}
}

/******************************************************************************
 * initStacks ...
 *
 * @param Pid global index of one element of a rendering tile (i.e. pixel)
 ******************************************************************************/
__device__
void initStacks( uint Pid )
{
	// Init shared stack
	S.init( Pid );
	nodeStack.init( Pid );
#if BVH_TRAVERSAL_USE_MASKSTACK
	nodeMaskStack.init(Pid);
#endif

	// Shared memory
	__shared__ VolTreeBVHNodeUser rootNode;
	if ( Pid == 0 )
	{
		rootNode.bbox.pMin = make_float3( 0.0f );
		rootNode.bbox.pMax = make_float3( 1.0f );
		rootNode.setSubNodeIdx( 2 );
		rootNode.setGPULink();
	}

#if BVH_TRAVERSAL_USE_MASKSTACK
	__shared__ uint blockMask;
	uint maskVal;
	maskVal=uint(!masked)<<Pid;
	atomicOr(&blockMask, maskVal);

	__syncthreads();
	if(Pid==0){
		nodeMaskStack.push(blockMask);
	}
#endif

	if ( Pid == 0 )
	{
		S.push( 0 );
		nodeStack.push( rootNode );
	}
	__syncthreads();
}


//EscapeIdx traversal

template<class GPUTreeBVHType>
__device__
void d_bvhTraversalStep_SharedEscape(GPUTreeBVHType &gpuTreeBVH, 
									 uint &Pid, int &maskedAt, 
									 uint2 &tileCoords, 
									 float3 &rayStart, float3 &rayDir, 
									 uint &Np, VolTreeBVHNodeUser &snode, 
									 float &t, float &lastInterT, float &lastInterTmax){

}

template<class GPUTreeBVHType>
__device__
inline void d_bvhBBoxInterStep_SharedEscape(GPUTreeBVHType &gpuTreeBVH, 
									 uint &Pid,
									 float3 &bboxMin, float3 &bboxMax, 
									 uint &Np, VolTreeBVHNodeUser &snode){

	float3 testSphereCenter;
	float testShereRadius;


	testSphereCenter=(bboxMin+bboxMax)/make_float3(2.0f);

	float3 bboxSize=bboxMax-bboxMin;
	testShereRadius=max(bboxSize.x, max(bboxSize.y, bboxSize.z))/2.0f;

	do{

		//gpuTreeBVH.parallelFetchBVHNode(Pid, snode, Np);
		gpuTreeBVH.fetchBVHNode(snode, Np);
		

		__syncthreads();

		__shared__ bool inter;

		inter=sphereBoxIntersect(testSphereCenter, testShereRadius, snode.bbox.pMin, snode.bbox.pMax);

		__syncthreads();

		if(inter && snode.isLinkActive()){

			if(snode.hasSubNodes()){
				Np=snode.getSubNodeIdx();
			}else{
				return;
			}

		}else{
			Np=snode.escapeIdx;
		}

		__syncthreads();

	}while(Np);
}



template<class GPUTreeBVHType>
__device__
inline void d_bvhCreateInterDataList(GPUTreeBVHType &gpuTreeBVH, 
									 uint &Pid,
									 float3 &bboxMin, float3 &bboxMax, 
									 uint *sharedDataIdxList, uint maxNumElem,
									 uint &numElem) 
{

	numElem=0;

	__shared__ uint Np;
	__shared__ VolTreeBVHNodeUser snode;

	Np=2;

	do{

		d_bvhBBoxInterStep_SharedEscape(gpuTreeBVH, Pid, bboxMin, bboxMax, Np, snode);

		//gpuTreeBVH.parallelFetchBVHNode(Pid, snode, Np);

		__syncthreads();


		if(Np){
			if( snode.isDataType() && snode.isLinkActive() ){

				if(Pid==0){
					sharedDataIdxList[numElem]=snode.getDataIdx();

					numElem++;

					
				}

			}
			
			Np=snode.escapeIdx;

		}

		__syncthreads();

	}while(Np && numElem<maxNumElem);
}

#endif

////BVHTrianglesManip.hcu
//#ifndef BVHTrianglesManip_hcu
//#define BVHTrianglesManip_hcu
//
///******************************************************************************
// ******************************* INCLUDE SECTION ******************************
// ******************************************************************************/
//
//// Gigavoxels
//#include <GvCore/IntersectionTests.hcu>
//#include <GvCore/RendererHelpers.hcu>
//
////#include "BvhTree.hcu"
////#include "IntersectionTests.h"
//
//__device__
//void groupParallelSum(uint Tid, int *data, uint n){
//	for(uint stride=n>>1; stride>0; stride=stride>>1){
//		__syncthreads();
//		if(Tid<stride){
//			data[Tid]+=data[Tid+stride];
//		}
//
//	}
//}
//
//__device__
//void groupParallelSum(uint Tid, float *data, uint n){
//	for(uint stride=n>>1; stride>0; stride=stride>>1){
//		__syncthreads();
//		if(Tid<stride){
//			data[Tid]+=data[Tid+stride];
//		}
//	}
//}
//
//__device__
//void groupParallelMin(uint Tid, float *data, uint n){
//	for(uint stride=n>>1; stride>0; stride=stride>>1){
//		if(Tid<stride){
//			data[Tid] = data[Tid] <= data[Tid+stride] ? data[Tid] : data[Tid+stride];
//			//data[Tid]=fminf(data[Tid], data[Tid+stride]);
//		}
//		__syncthreads();
//	}
//}
//
//
//__device__
//inline void groupParallelOR(uint Tid, uint *data, uint n){
//	for(uint stride=n>>1; stride>0; stride=stride>>1){
//		__syncthreads();
//		if(Tid<stride){
//			data[Tid]=data[Tid] | data[Tid+stride];
//		}
//
//	}
//}
//
///** BVH traversal using shared stack. 'Realtime Ray Tracing on GPU with BVH-based Packet Traversal' */
//template<class T>
//class TraversalStack{
//public:
//	int curIndex;
//	T data[BVH_TRAVERSAL_STACK_SIZE];
//
//	__device__
//	void init(uint Pid){
//		if(Pid==0)
//			curIndex=0;
//		__syncthreads();
//	}
//
//	__device__
//	inline T &top(){
//		return data[curIndex];
//	}
//
//
//	__device__
//	inline T pop(uint Pid){
//		if(Pid==0		&& curIndex>0)
//			curIndex--;
//		//__syncthreads();
//		return data[curIndex];
//	}
//
//	__device__
//	inline T pop(){
//		//if(curIndex>0)
//			curIndex--;
//		return data[curIndex];
//	}
//
//	__device__
//	inline void push(uint Pid, const T &val){
//		if(Pid==0){
//			if(curIndex<BVH_TRAVERSAL_STACK_SIZE	  && curIndex>=0){
//				data[curIndex]=val;
//				curIndex++;
//			}
//		}
//	}
//	__device__
//	inline void push(const T &val){
//		//if(curIndex<BVH_TRAVERSAL_STACK_SIZE		&& curIndex>=0){
//			data[curIndex]=val;
//			curIndex++;
//		//}
//	}
//
//	__device__
//	inline bool isEmpty(){
//		//__syncthreads();
//		return (curIndex<=0);
//	}
//	__device__
//	inline bool isFull(){
//		//__syncthreads();
//		return (curIndex>=BVH_TRAVERSAL_STACK_SIZE);
//	}
//
//};
//
//
//template<class T, uint Size>
//struct CudaQueue{
//
//	T data[Size];
//
//	__device__
//	inline void clear(T v){
//		switch(Size){
//		case 8:
//			data[7]=v;
//		case 7:
//			data[6]=v;
//		case 6:
//			data[5]=v;
//		case 5:
//			data[4]=v;
//		case 4:
//			data[3]=v;
//		case 3:
//			data[2]=v;
//		case 2:
//			data[1]=v;
//		case 1:
//			data[0]=v;
//		}
//	}
//
//
//	__device__
//	inline T &top(){
//		return data[0];
//	}
//
//	__device__
//	inline void push(const T &val){
//		switch(Size){
//		case 8:
//			data[7]=data[6];
//		case 7:
//			data[6]=data[5];
//		case 6:
//			data[5]=data[4];
//		case 5:
//			data[4]=data[3];
//		case 4:
//			data[3]=data[2];
//		case 3:
//			data[2]=data[1];
//		case 2:
//			data[1]=data[0];
//		}
//
//		data[0]=val;
//	}
//};
//
//
//
//__shared__ TraversalStack<uint> S;
//__shared__ TraversalStack<VolTreeBVHNodeUser> nodeStack;
//
//#define STACKALL_MODE 0
//
//template<class GPUTreeBVHType>
//__device__
//void d_bvhTraversalStep_SharedStack(GPUTreeBVHType &gpuTreeBVH, uint &Pid, int &maskedAt, uint2 &tileCoords, float3 &rayStart, float3 &rayDir, uint &Np, VolTreeBVHNodeUser &snode, float &t){
//
//	//__shared__ VolTreeBVHNodeUser snode;
//	__shared__ bool stopTraversal;
//
//
//	if(S.isEmpty()){
//		maskedAt=-1;
//	}
//
//	if(Pid==0){
//		Np=S.pop();
//		snode=nodeStack.pop();
//	}
//	__syncthreads();
//
//
//	if(Pid==0){
//		stopTraversal=true;
//	}
//	__syncthreads();
//
//	if(maskedAt!=-1 && snode.hasSubNodes()){
//		stopTraversal=false;
//	}
//	__syncthreads();
//
//
//
//	while( !stopTraversal ){
//
//		if(maskedAt>S.curIndex ){
//			maskedAt=BVH_TRAVERSAL_STACK_SIZE;
//
//			//Intersect ray with BVH node
//			float interMin; float interMax;
//			int objboxinter=intersectBox( rayStart, rayDir,  snode.bbMin(), snode.bbMax(), interMin, interMax);
//			bool snodeInter= (objboxinter && interMax>0.0f);
//			interMin=maxcc(interMin, 0.0f);
//
//			if(!snodeInter){
//				maskedAt=S.curIndex;
//			}else if(interMin>t){
//				maskedAt=S.curIndex;
//			}
//		}
//		__syncthreads();
//
//
//		__shared__ VolTreeBVHNodeUser Nlr[2];
//		__shared__ uint sharedHits[4];
//		__shared__ float M[NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y ]; //BVH_NUM_THREADS_PER_BLOCK_X*BVH_NUM_THREADS_PER_BLOCK_Y
//
//		uint b1, b2;
//		float lambda1; float lambda2;
//		float mu1; float mu2;
//
//		//Parallel fetch of the 2 childs
//		gpuTreeBVH.parallelFetchBVHNode(Pid, Nlr[0], snode.getSubNodeIdx());
//		//__syncthreads();
//		gpuTreeBVH.parallelFetchBVHNode(Pid, Nlr[1], snode.getSubNodeIdx()+1);
//		//__syncthreads();
//
//		int objboxinter;
//		//Intersect ray with BVH node
//		bool hitobjectLambda;
//		bool hitobjectMu;
//
//		if(maskedAt>S.curIndex  /*&& maskedAt!=-1*/){
//			objboxinter=intersectBox( rayStart, rayDir,  Nlr[0].bbMin(), Nlr[0].bbMax(), lambda1, lambda2);
//			hitobjectLambda=objboxinter && lambda2>0.0f;
//			lambda1=maxcc(lambda1, 0.0f);
//
//
//			objboxinter=intersectBox( rayStart, rayDir,  Nlr[1].bbMin(), Nlr[1].bbMax(), mu1, mu2);
//			hitobjectMu=objboxinter && mu2>0.0f;
//			mu1=maxcc(mu1, 0.0f);
//
//		}else{
//			hitobjectLambda=false;
//			hitobjectMu=false;
//		}
//
//
//		b1 =(uint)(hitobjectLambda );
//		b2 =(uint)(hitobjectMu );
//
//		if(Pid<4)
//			sharedHits[Pid]=0;
//		__syncthreads();
//
//		sharedHits[2*b1+b2]=true;
//		__syncthreads();
//
//		if(  sharedHits[3] || (sharedHits[1] && sharedHits[2]) ){
//
//			/*if(Pid==0)
//				M[0]=-1;*/
//			float b2state= (b2 && mu1<lambda1) ? 1.0f : 0.0f;
//
//			if(!b1 && !b2)
//				b2state=0.5f;
//
//			M[Pid]=2.0f* b2state -1.0f;
//
//			__syncthreads();
//
//
//			groupParallelSum( Pid, M, NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y /*BVH_NUM_THREADS_PER_BLOCK_X*BVH_NUM_THREADS_PER_BLOCK_Y*/);
//			/*if(Pid==0){
//				float summ=0.0f;
//
//				for(uint ii=0; ii<NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y; ii++){
//					summ+=M[ii];
//				}
//				M[0]=summ;
//			}*/
//			__syncthreads();
//
//
//			if(M[0]<0.0f){
//
//				/*if(maskedAt>S.curIndex && !b2)
//					maskedAt=S.curIndex;*/
//				if(Pid==0){
//					S.push(snode.getSubNodeIdx()+1);
//					nodeStack.push(Nlr[1]);
//				}
//				__syncthreads();
//
//				/*if(maskedAt>S.curIndex && !b1)
//					maskedAt=S.curIndex;*/
//				if(Pid==0){
//#if STACKALL_MODE
//					S.push(snode.getSubNodeIdx());
//					nodeStack.push(Nlr[0]);
//#else
//					Np=snode.getSubNodeIdx();
//					snode=Nlr[0];
//#endif
//				}
//				//__syncthreads();
//
//
//			}else{
//				/*if(maskedAt>S.curIndex && !b1)
//					maskedAt=S.curIndex;*/
//				if(Pid==0){
//					S.push(snode.getSubNodeIdx());
//					nodeStack.push(Nlr[0]);
//				}
//				__syncthreads();
//				/*if(maskedAt>S.curIndex && !b2)
//					maskedAt=S.curIndex;*/
//				if(Pid==0){
//#if STACKALL_MODE
//					S.push(snode.getSubNodeIdx()+1);
//					nodeStack.push(Nlr[1]);
//#else
//					Np=snode.getSubNodeIdx()+1;
//					snode=Nlr[1];
//#endif
//				}
//				//__syncthreads();
//			}
//
//			//__syncthreads();
//
//		}else{
//
//			if(sharedHits[2]){ //Warning, M[2] and M[1] cases inverted in the original paper algorithm
//				if(maskedAt>S.curIndex && !b1		  /*&& maskedAt!=-1*/)
//						maskedAt=S.curIndex;
//
//				if(Pid==0){
//#if STACKALL_MODE
//					S.push(snode.getSubNodeIdx());
//					nodeStack.push(Nlr[0]);
//#else
//					Np=snode.getSubNodeIdx();
//					snode=Nlr[0];
//#endif
//				}
//				//__syncthreads();
//			}else if(sharedHits[1]){
//
//				if(maskedAt>S.curIndex && !b2	 /*&& maskedAt!=-1*/)
//					maskedAt=S.curIndex;
//
//				if(Pid==0){
//#if STACKALL_MODE
//					S.push(snode.getSubNodeIdx()+1);
//					nodeStack.push(Nlr[1]);
//#else
//					Np=snode.getSubNodeIdx()+1;
//					snode=Nlr[1];
//#endif
//				}
//				//__syncthreads();
//			}
//#if STACKALL_MODE==0
//			else{
//
//				if(S.isEmpty()){
//					maskedAt=-1;
//				}else{
//					if(Pid==0){
//						Np=S.pop();
//						snode=nodeStack.pop();
//					}
//				}
//				//__syncthreads();
//			}
//#endif
//
//		}
//
//		__syncthreads();
//
//#if STACKALL_MODE
//		if(S.isEmpty()){
//			maskedAt=-1;
//		}
//
//		__syncthreads();
//		if(Pid==0){
//			Np=S.pop();
//			snode=nodeStack.pop();
//		}
//		__syncthreads();
//#endif
//		if(Pid==0)
//			stopTraversal=true;
//		__syncthreads();
//
//		if( maskedAt!=-1 && snode.hasSubNodes() ){
//			stopTraversal=false;
//		}
//		__syncthreads();
//
//	}
//}
//
//
//#if BVH_TRAVERSAL_USE_MASKSTACK
//__shared__ TraversalStack<uint> nodeMaskStack;
//#endif
//
//template < typename BvhTreeKernelType >
//__device__
//void d_bvhTraversalStep_SharedStack2(BvhTreeKernelType &gpuTreeBVH, const uint Pid, int &maskedAt, const float3 rayStart, const float3 rayDir,
//	uint &Np, VolTreeBVHNodeUser &snode, float &t, float &lastInterT, float &lastInterTmax)
//{
//	//__shared__ VolTreeBVHNodeUser snode;
//	__shared__ bool stopTraversal;
//
//	stopTraversal=false;
//
//	while (!stopTraversal)
//	{
//		if (Np == 0)
//		{
//			// Pop the current node from the stack
//			if (Pid == 0)
//			{
//				Np = S.pop();
//				snode = nodeStack.pop();
//			}
//
//			__syncthreads();
//
//			if (maskedAt > S.curIndex)
//			{
//				//Intersect ray with BVH node
//				float interMin=0.0f; float interMax=1000.0f;
//				int objboxinter=intersectBox( rayStart, rayDir,  snode.bbMin(), snode.bbMax(), interMin, interMax);
//				bool snodeInter= (objboxinter && interMax>0.0f);
//				//interMin=maxcc(interMin, 0.0f);
//
//				lastInterT=interMin;
//				lastInterTmax=interMax;
//
//				// FIXME:
//				float pixelSize = k_renderViewContext.pixelSize.x * interMin * 1.333f * k_renderViewContext.frustumNearINV;
//				//float pixelSize=getPixelSizeAtDist<0>(interMin)*1.0f;
//
//				if (!snodeInter || interMin>t || snode.bbox.maxSize() < pixelSize) {
//					maskedAt = S.curIndex;
//				} else {
//					maskedAt = BVH_TRAVERSAL_STACK_SIZE;
//				}
//			}
//
//			if (!snode.hasSubNodes())
//				break;
//
//		} //if(Np==0)
//
//		__shared__ VolTreeBVHNodeUser Nlr[2];
//		__shared__ uint sharedHits[4];
//		__shared__ float M[NUM_RAYS_PER_BLOCK_X*NUM_RAYS_PER_BLOCK_Y];
//
//		//Parallel fetch of the 2 childs
//		gpuTreeBVH.parallelFetchBVHNodeTile(Pid, Nlr, snode.getSubNodeIdx());
//
//		float interTNear[2]; float interTFar[2];
//		interTNear[0]=interTNear[1]=0.0f; interTFar[0]=interTFar[1]=1000.0f;
//
//		int objboxinter;
//		//Intersect ray with BVH node
//		bool hitobject[2];
//
//		if (maskedAt > S.curIndex/*&& maskedAt!=-1*/)
//		{
//			objboxinter = intersectBox(rayStart, rayDir,  Nlr[0].bbMin(), Nlr[0].bbMax(), interTNear[0], interTFar[0]);
//			hitobject[0] = objboxinter && interTFar[0]>0.0f;
//			//interTNear[0]=maxcc(interTNear[0], 0.0f);
//
//			objboxinter = intersectBox(rayStart, rayDir,  Nlr[1].bbMin(), Nlr[1].bbMax(), interTNear[1], interTFar[1]);
//			hitobject[1] = objboxinter && interTFar[1]>0.0f;
//			//interTNear[1]=maxcc(interTNear[1], 0.0f);
//		}
//		else
//		{
//			hitobject[0] = false;
//			hitobject[1] = false;
//		}
//
//		///////////////////////
//		uint b1, b2;
//
//		b1 =(uint)(hitobject[0] && interTNear[0] <= t);
//		b2 =(uint)(hitobject[1] && interTNear[1] <= t);
//
//		///////////////////////
//		if(Pid<4)
//			sharedHits[Pid]=0;
//		__syncthreads();
//
//		sharedHits[2*b1+b2]=true;
//		__syncthreads();
//
//		if (sharedHits[3] || (sharedHits[1] && sharedHits[2]))
//		{
//			float b2state= (b2 && interTNear[1]<interTNear[0]) ? 1.0f : 0.0f;
//
//			if (!b1 && !b2)
//				b2state=0.5f;
//
//			M[Pid] = 2.0f * b2state -1.0f;
//			__syncthreads();
//
//			groupParallelSum(Pid, M, NUM_RAYS_PER_BLOCK_X * NUM_RAYS_PER_BLOCK_Y);
//			__syncthreads();
//
//			if (M[0] < 0.0f)
//			{
//				if (Pid == 0)
//				{
//					S.push(snode.getSubNodeIdx() + 1);
//					nodeStack.push(Nlr[1]);
//				}
//				__syncthreads();
//
//
//				if (Pid == 0)
//				{
//					Np=snode.getSubNodeIdx();
//					snode=Nlr[0];
//				}
//				//__syncthreads();
//
//				lastInterT=interTNear[0];
//				lastInterTmax=interTFar[0];
//
//				if (maskedAt > S.curIndex && !b1)
//					maskedAt = S.curIndex;
//			}
//			else
//			{
//				if (Pid == 0)
//				{
//					S.push(snode.getSubNodeIdx());
//					nodeStack.push(Nlr[0]);
//				}
//				__syncthreads();
//
//				if (Pid == 0)
//				{
//					Np=snode.getSubNodeIdx()+1;
//					snode=Nlr[1];
//				}
//				//__syncthreads();
//
//				lastInterT=interTNear[1];
//				lastInterTmax=interTFar[1];
//
//				if (maskedAt > S.curIndex && !b2)
//					maskedAt = S.curIndex;
//			}
//			//__syncthreads();
//		}
//		else
//		{
//			if (sharedHits[2]) //Warning, M[2] and M[1] cases inverted in the original paper algorithm
//			{
//				if (maskedAt > S.curIndex && !b1)
//					maskedAt = S.curIndex;
//
//				if (Pid == 0)
//				{
//					Np=snode.getSubNodeIdx();
//					snode=Nlr[0];
//				}
//				//__syncthreads();
//
//				lastInterT=interTNear[0];
//				lastInterTmax=interTFar[0];
//			}
//			else if(sharedHits[1])
//			{
//				if (maskedAt > S.curIndex && !b2)
//					maskedAt = S.curIndex;
//
//				if (Pid == 0)
//				{
//					Np=snode.getSubNodeIdx()+1;
//					snode=Nlr[1];
//				}
//				//__syncthreads();
//
//				lastInterT=interTNear[1];
//				lastInterTmax=interTFar[1];
//			}
//			else
//			{
//				if (S.isEmpty())
//				{
//					maskedAt=-1;
//				}
//				else
//				{
//					//Pop required
//					Np=0;
//				}
//				//__syncthreads();
//			}
//
//		}
//
//		__syncthreads();
//
//		if (Pid == 0)
//			stopTraversal = true;
//		__syncthreads();
//
//		if (maskedAt != -1 && (Np==0 || snode.hasSubNodes())) {
//			stopTraversal=false;
//		}
//		__syncthreads();
//	}
//}
//
//__device__
//void initStacks(uint Pid)
//{
//	//Init shared stack
//	S.init(Pid);
//	nodeStack.init(Pid);
//
//	__shared__ VolTreeBVHNodeUser rootNode;
//
//	if(Pid==0)
//	{
//		rootNode.bbox.pMin=make_float3(0.0f);
//		rootNode.bbox.pMax=make_float3(1.0f);
//		rootNode.setSubNodeIdx(2);
//		rootNode.setGPULink();
//	}
//
//	if(Pid==0)
//	{
//		S.push(0);
//		nodeStack.push(rootNode);
//	}
//
//	__syncthreads();
//}
//
////EscapeIdx traversal
//
////template<class GPUTreeBVHType>
////__device__
////void d_bvhTraversalStep_SharedEscape(GPUTreeBVHType &gpuTreeBVH, 
////									 uint &Pid, int &maskedAt, 
////									 uint2 &tileCoords, 
////									 float3 &rayStart, float3 &rayDir, 
////									 uint &Np, VolTreeBVHNodeUser &snode, 
////									 float &t, float &lastInterT, float &lastInterTmax){
////
////}
////
////template<class GPUTreeBVHType>
////__device__
////inline void d_bvhBBoxInterStep_SharedEscape(GPUTreeBVHType &gpuTreeBVH, 
////									 uint &Pid,
////									 float3 &bboxMin, float3 &bboxMax, 
////									 uint &Np, VolTreeBVHNodeUser &snode){
////
////	float3 testSphereCenter;
////	float testShereRadius;
////
////
////	testSphereCenter=(bboxMin+bboxMax)/make_float3(2.0f);
////
////	float3 bboxSize=bboxMax-bboxMin;
////	testShereRadius=max(bboxSize.x, max(bboxSize.y, bboxSize.z))/2.0f;
////
////	do{
////
////		//gpuTreeBVH.parallelFetchBVHNode(Pid, snode, Np);
////		gpuTreeBVH.fetchBVHNode(snode, Np);
////		
////
////		__syncthreads();
////
////		__shared__ bool inter;
////
////		inter=sphereBoxIntersect(testSphereCenter, testShereRadius, snode.bbox.pMin, snode.bbox.pMax);
////
////		__syncthreads();
////
////		if(inter && snode.isLinkActive()){
////
////			if(snode.hasSubNodes()){
////				Np=snode.getSubNodeIdx();
////			}else{
////				return;
////			}
////
////		}else{
////			Np=snode.escapeIdx;
////		}
////
////		__syncthreads();
////
////	}while(Np);
////}
//
//
//
////template<class GPUTreeBVHType>
////__device__
////inline void d_bvhCreateInterDataList(GPUTreeBVHType &gpuTreeBVH, 
////									 uint &Pid,
////									 float3 &bboxMin, float3 &bboxMax, 
////									 uint *sharedDataIdxList, uint maxNumElem,
////									 uint &numElem) 
////{
////
////	numElem=0;
////
////	__shared__ uint Np;
////	__shared__ VolTreeBVHNodeUser snode;
////
////	Np=2;
////
////	do{
////
////		d_bvhBBoxInterStep_SharedEscape(gpuTreeBVH, Pid, bboxMin, bboxMax, Np, snode);
////
////		//gpuTreeBVH.parallelFetchBVHNode(Pid, snode, Np);
////
////		__syncthreads();
////
////
////		if(Np){
////			if( snode.isDataType() && snode.isLinkActive() ){
////
////				if(Pid==0){
////					sharedDataIdxList[numElem]=snode.getDataIdx();
////
////					numElem++;
////
////					
////				}
////
////			}
////			
////			Np=snode.escapeIdx;
////
////		}
////
////		__syncthreads();
////
////	}while(Np && numElem<maxNumElem);
////}
//
//#endif
